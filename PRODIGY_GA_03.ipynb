{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8023bae2",
   "metadata": {},
   "source": [
    "# ğŸŒŸ **Internship Task 3  at Prodigy Infotec: Generative AI Intern**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "363d8402",
   "metadata": {},
   "source": [
    "## ğŸ“ **Text Generation with Markov Chains**\n",
    "\n",
    "### ğŸ¯ **Task 3 Overview:**\n",
    "In this project, you will implement a simple text generation algorithm using **Markov chains**. The goal is to create a statistical model that predicts the next character or word in a sequence based on the previous one(s). This technique can be used for generating text that mimics the style of a given input text.\n",
    "\n",
    "Markov chains are a type of probabilistic model where the future state depends only on the current state, not on the sequence of events that preceded it. In text generation, this means predicting the next word or character based on the previous one.\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ› ï¸ **How Youâ€™ll Achieve This:**\n",
    "\n",
    "1. **Understand Markov Chains:**\n",
    "   - The core idea behind Markov chains is that the probability of a given event (e.g., a character or word) depends only on the state of the previous event. This property makes Markov chains ideal for modeling sequential data, like text.\n",
    "\n",
    "2. **Text Preprocessing**:\n",
    "   - You'll begin by preparing your input text. This involves:\n",
    "     - **Cleaning** the text (removing unwanted characters, formatting, etc.).\n",
    "     - **Tokenization**: Breaking the text into words or characters, depending on whether you're working with word-based or character-based models.\n",
    "     - **Creating n-grams**: For Markov chains, you will create \"n-grams\" (pairs, triplets, etc.) that help define the relationship between words or characters.\n",
    "\n",
    "3. **Build the Markov Chain Model**:\n",
    "   - You'll create a model where:\n",
    "     - **States** are words or characters.\n",
    "     - **Transitions** are the probabilities of moving from one word/character to another.\n",
    "   - This can be done by iterating through the text and counting the occurrences of word/character pairs or n-grams.\n",
    "\n",
    "4. **Train the Model**:\n",
    "   - You'll create a transition matrix that captures the probabilities of each word or character following another.\n",
    "   - The transition matrix is essentially a dictionary where keys are words/characters, and the values are dictionaries of possible next words/characters with their associated probabilities.\n",
    "\n",
    "5. **Generate Text**:\n",
    "   - Once the model is trained, you can use it to generate new text. Starting from an initial word or character, the model predicts the next word/character based on the learned probabilities.\n",
    "   - This process can be repeated iteratively to generate a sequence of text.\n",
    "\n",
    "6. **Text Generation Process**:\n",
    "   - You can implement different strategies for generating text, such as:\n",
    "     - **Greedy approach**: Always choose the most probable next word/character.\n",
    "     - **Random sampling**: Randomly sample the next word/character according to its probability distribution.\n",
    "\n",
    "7. **Evaluate the Output**:\n",
    "   - After generating the text, you will evaluate it for coherence and style, comparing it with the original input text.\n",
    "   - Depending on the model's performance, you may need to adjust the size of n-grams or refine your text generation strategies.\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸš€ **Outcome:**\n",
    "\n",
    "By the end of this project, you will have:\n",
    "- Implemented a **Markov chain** model for text generation.\n",
    "- Gained hands-on experience in **statistical modeling** and text processing.\n",
    "- Created an application capable of generating text that mimics the style of a provided input.\n",
    "\n",
    "This task will provide you with a strong foundation in **probabilistic modeling** and the ability to work with sequential data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6a76f7b",
   "metadata": {},
   "source": [
    "## ğŸ”„ Generating Text with Markov Chains  \n",
    "\n",
    "### Steps:  \n",
    "1. ğŸ“œ **Prepare the Corpus**  \n",
    "   - Defines a block of text as the dataset for generating new text.  \n",
    "\n",
    "2. ğŸ”¢ **Understanding Markov Chains**  \n",
    "   - Uses probability-based transitions between words to generate coherent sequences.  \n",
    "\n",
    "3. ğŸ² **Randomization**  \n",
    "   - The system will randomly select and transition between words based on their frequency and order in the corpus.  \n",
    "\n",
    "4. âœ… **Ready for Text Generation**  \n",
    "   - The prepared corpus will be processed to create a Markov model for generating new text.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d95bb14f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "# Step 1: Prepare the corpus (you can change this text)\n",
    "text = \"\"\"\n",
    "Markov chains are mathematical systems that undergo transitions from one state to another.\n",
    "They are used in various fields including physics, economics, and computer science.\n",
    "Markov chains are named after Andrey Markov, a Russian mathematician who developed the theory.\n",
    "They are useful for modeling random systems that follow a certain probability distribution.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90d3006b",
   "metadata": {},
   "source": [
    "## âœ‚ï¸ Tokenizing Text for Markov Chains  \n",
    "\n",
    "### Steps:  \n",
    "1. ğŸ“œ **Receive the Input Text**  \n",
    "   - Uses the predefined corpus containing multiple sentences.  \n",
    "\n",
    "2. ğŸ”  **Split into Words**  \n",
    "   - Breaks the text into individual words to create a sequence.  \n",
    "\n",
    "3. ğŸ”— **Prepare for Markov Model**  \n",
    "   - These words will be used to build transitions between states for text generation.  \n",
    "\n",
    "4. âœ… **Ready for Processing**  \n",
    "   - The tokenized words can now be used to form a probability-based Markov chain.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3c75a506",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Tokenize the text (split into words)\n",
    "words = text.split()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe5ae013",
   "metadata": {},
   "source": [
    "## ğŸ”— Building a Markov Chain Model  \n",
    "\n",
    "### Steps:  \n",
    "1. ğŸ“Œ **Initialize an Empty Dictionary**  \n",
    "   - Creates a dictionary where each word maps to its possible next words.  \n",
    "\n",
    "2. ğŸ”„ **Loop Through the Tokenized Words**  \n",
    "   - Iterates through the word list, taking each word and its next word as key-value pairs.  \n",
    "\n",
    "3. ğŸ“Š **Update the Markov Chain Dictionary**  \n",
    "   - If the word is new, it is added with its next word as a value.  \n",
    "   - If it already exists, the next word is appended to its list of possible successors.  \n",
    "\n",
    "4. âœ… **Ready for Text Generation**  \n",
    "   - The Markov chain model is now structured to generate text based on probability distributions.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3ad132e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Create a Markov Chain Model\n",
    "# Create a dictionary where each word is linked to the next possible word(s)\n",
    "markov_chain = {}\n",
    "\n",
    "for i in range(len(words) - 1):\n",
    "    word = words[i]\n",
    "    next_word = words[i + 1]\n",
    "    \n",
    "    # If word is already a key, append the next word to the list\n",
    "    if word not in markov_chain:\n",
    "        markov_chain[word] = [next_word]\n",
    "    else:\n",
    "        markov_chain[word].append(next_word)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06ba5afa",
   "metadata": {},
   "source": [
    "## âœ¨ Generating Text with Markov Chains  \n",
    "\n",
    "### Steps:  \n",
    "1. ğŸš€ **Define a Function for Text Generation**  \n",
    "   - Takes a starting word and a desired length for the generated text.  \n",
    "\n",
    "2. ğŸ”„ **Iterate to Form a Sentence**  \n",
    "   - Repeatedly selects the next word based on the Markov Chain model.  \n",
    "\n",
    "3. ğŸ² **Random Selection of Next Word**  \n",
    "   - Chooses a word from the list of possible next words using probability-based transitions.  \n",
    "\n",
    "4. â›” **Handle Missing Words**  \n",
    "   - Stops if a word has no further connections in the chain.  \n",
    "\n",
    "5. ğŸ“ **Return the Generated Text**  \n",
    "   - Joins the words into a complete sentence for output.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c0864445",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Function to generate text based on the Markov Chain model\n",
    "def generate_text(start_word, length=50):\n",
    "    current_word = start_word\n",
    "    generated_text = [current_word]\n",
    "    \n",
    "    for _ in range(length - 1):\n",
    "        if current_word not in markov_chain:\n",
    "            break\n",
    "        \n",
    "        next_word = random.choice(markov_chain[current_word])  # Randomly select the next word\n",
    "        generated_text.append(next_word)\n",
    "        current_word = next_word\n",
    "    \n",
    "    return ' '.join(generated_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e42aae3a",
   "metadata": {},
   "source": [
    "## ğŸ“ Generating and Printing Markov Chain Text  \n",
    "\n",
    "### Steps:  \n",
    "1. ğŸ¯ **Select a Random Start Word**  \n",
    "   - Picks a word from the tokenized text as the starting point for generation.  \n",
    "\n",
    "2. ğŸ”„ **Generate Text**  \n",
    "   - Calls the `generate_text` function to create a sequence of 100 words based on the Markov Chain model.  \n",
    "\n",
    "3. ğŸ–¨ï¸ **Print the Output**  \n",
    "   - Displays the generated text for review and analysis.  \n",
    "\n",
    "4. âœ… **Result**  \n",
    "   - A probabilistic sequence of words mimicking the original corpus is produced.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6e2bb507",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Text:\n",
      "random systems that undergo transitions from one state to another. They are mathematical systems that follow a certain probability distribution.\n"
     ]
    }
   ],
   "source": [
    "start_word = random.choice(words)  # Choose a random starting word\n",
    "generated_text = generate_text(start_word, length=100)\n",
    "\n",
    "# Print the generated text\n",
    "print(\"Generated Text:\")\n",
    "print(generated_text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c77fe40d",
   "metadata": {},
   "source": [
    "## ğŸ“ Generating and Printing Markov Chain Text  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b0d82e9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Text:\n",
      "systems that follow a Russian mathematician who developed the theory. They are named after Andrey Markov, a certain probability distribution.\n"
     ]
    }
   ],
   "source": [
    "start_word = random.choice(words)  # Choose a random starting word\n",
    "generated_text = generate_text(start_word, length=150)\n",
    "\n",
    "# Print the generated text\n",
    "print(\"Generated Text:\")\n",
    "print(generated_text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6239bd2",
   "metadata": {},
   "source": [
    "## ğŸ“ Generating and Printing Markov Chain Text  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "be9a1d14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Text:\n",
      "state to another. They are mathematical systems that follow a certain probability distribution.\n"
     ]
    }
   ],
   "source": [
    "start_word = random.choice(words)  # Choose a random starting word\n",
    "generated_text = generate_text(start_word, length=50)\n",
    "\n",
    "# Print the generated text\n",
    "print(\"Generated Text:\")\n",
    "print(generated_text)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
